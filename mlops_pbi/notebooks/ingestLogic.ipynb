{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\"> Notebook Information </p>\n",
    "\n",
    "<table style=\"color:rgb(88,89,91); font-family:Arial; float:left; font-size:13px; text-align:left;\">\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Report</b></td>\n",
    "<td style=\"text-align:left;\">Exploratory Data Analysis and Automated ETL pipeline for PowerBI Audit Log </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Author</b></td>\n",
    "<td style=\"text-align:left;\">Sanmi Ibitoye</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Email</b></td>\n",
    "<td style=\"text-align:left;\">Sanmi.Ibitoye@hs2.org.uk</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Summary</b></td>\n",
    "<td style=\"text-align:left;\">This notebook forms the basis of all future etl, tools and infrastructure doployable in relation to PowerBI Audit Log Report project. <br>\n",
    "Initial analysis and exploration helps unearth the data so that its shape, format and condition is understood by team memebers and explainable to stakeholders. <br>\n",
    "The resulting pipelines and infrastructure will employ the use of technology stacks such as git, postgres, docker, dbt, bespoke python libraries, airbyte and <br> prefect for automation, ochestration and compute. Alternative stack could also be implemented<br>\n",
    "This will serve a powerbi dashboard data for its vizualisation and translation to english for the stakeholder <br>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Date</b></td>\n",
    "<td style=\"text-align:left;\">Last Updated: 08 - 12 - 2022 </td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the required library Imports\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from functools import wraps\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    import json\n",
    "    import math\n",
    "\n",
    "    # import dask\n",
    "    # from dask.distributed import Client\n",
    "    # import dask.dataframe as dd\n",
    "    # import dask.multiprocessing\n",
    "    import yaml\n",
    "    import base64\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "\n",
    "    # display(HTML(\"<style>.container {width:90% !important;}<style/>\"))\n",
    "\n",
    "    # datetime libraries\n",
    "    import datetime\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    from functools import wraps\n",
    "    from calendar import monthrange\n",
    "    import datetime as dt\n",
    "    import time\n",
    "\n",
    "    # prefect libraries\n",
    "    from prefect import task, Flow\n",
    "\n",
    "    # from prefect.schedules import IntervalSchedule\n",
    "\n",
    "    # plotting libraries\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # profiling libraries\n",
    "    # from pandas_profiling import ProfileReport\n",
    "\n",
    "    # config libraries\n",
    "    import hydra\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    from hydra import utils\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Some Modules are Missing : {} \".format(e))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\">1 - Turn multiple csv into a single pandas dataframe.</p>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 1.1 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">The Power BI Activily Log data is extracted using a powershell script that only allows an API call of maximum 30 days from current date. <br>\n",
    "A single csv file holds the data for each day of selected columns defined in the powershell script. Each day represented by a csv file is stacked into a single pandas dataframe prior to subsequent analysis</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 1.2 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">The CSV files are obtained using a shell script. Although atleast 4 methods of interacting with the API exists, the option used in this solution fetches satisfies all possible user requirements known now and any unkown in the future <br>\n",
    "The 74 columns extracted holds a set of operations, all of which fall within the common activities that 98% of Power BI users will execute.<br> Analysis of the raw data has shown that the other operations which are rare and not relevant to the audit purpose often come through as blanks.</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 1.3 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">Using glob.glob works differently on Ubuntu compared to Windows <br>\n",
    "The file location is passed as a variable so when configuring or debugging, attention should be given to glob.glob pattern that applies to host system</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\">Ref. Bash Script</td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">https://community.powerbi.com/t5/Service/User-activities-by-Powershell/m-p/2071415</td>\n",
    "</tr>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import helper from src folder\n",
    "from mlops_pbi.src.helper import load_config\n",
    "\n",
    "# load raw files and concat into single data frame using columns defined above as column names for the dataframe to be created.\n",
    "@hydra.main(config_path=\"config\", config_name=\"main\", version_base=\"1.2\")\n",
    "def load_raw_files(config: DictConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load raw files and concat into single data frame using columns defined above as column names for the dataframe to be created.\n",
    "    \"\"\"\n",
    "    all_df = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(\n",
    "                one_filename,\n",
    "                low_memory=config.raw_data.low_memory,\n",
    "                header=config.raw_data.header,\n",
    "                sep=\",\",\n",
    "                encoding=config.raw_data.encoding,\n",
    "                names=config.raw_data.names,\n",
    "            )\n",
    "            for one_filename in glob.glob(config.raw_data.path)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "# assign function to a variable and loads dataframe into memory for subsequent analysis with the specified columns\n",
    "\n",
    "config = load_config()\n",
    "df = load_raw_files(config)\n",
    "\n",
    "# df.columns = columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optional - save dataframe to csv\n",
    "# df_raw_profile = ProfileReport(df, title=\"PowerBI AuditLog Raw Data Profiling Report\", explorative=True)\n",
    "# df_raw_profile.to_file(\"df_raw_profile.html\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\">2 - Run transformation pipeline on multiple csv concatenated into a single pandas dataframe.</p>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 2.1 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">The Power BI Activily Log data extracted using a powershell script has now been concatenated into a single dataframe. <br>\n",
    "A single dataframe holds all the data in memory. The tansformation pipeline makes a copy of the dataframe to avoid mutations on the original copy. <br> The pipeline is then run on the copy of the dataframe and the original dataframe is left untouched. <br> Date columns are converted to datetime format. <br> The datetime column is used to extract the month, year and day.\n",
    "</td>\n",
    "</td>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 2.2 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">The raw data contains logs that relate to the service account used to fetch the data. These logs skew the data and don't represent a user's activity. <br> As such, the last step in the initial transformation is to filter such logs out. <br> The service account API calls are logged with a unique reference of multiple 0 values. This values is passed as a parameter for the filtering out of all logs not related to an actual user. <br>\n",
    "The 36 columns extracted holds a set of operations, all of which fall within the common activities that 98% of Power BI users will execute.<br> Analysis of the raw data has shown that the other operations which are rare and not relevant to the audit purpose often come through as blanks.</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 2.3 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">This first node in the pipeline is stored as variable \"use_df\" <br>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\">Ref. Bash Script</td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">https://community.powerbi.com/t5/Service/User-activities-by-Powershell/m-p/2071415</td>\n",
    "</tr>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import python functions to build pipeline\n",
    "from mlops_pbi.src.first_ingestion_point import (\n",
    "    start_pipeline_pbia,\n",
    "    format_datatype_dates,\n",
    "    add_month_year_cols_users,\n",
    "    api_calls_filtered_out,\n",
    "    lower_case_cols,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# variables for the 4th transformation node i.e. api_calls_filtered_out\n",
    "service_account = \"SA_DAL_PowerBI@hs2.org.uk\"\n",
    "operation = \"ExportActivityEvents\"\n",
    "\n",
    "\n",
    "use_df = (\n",
    "    df.pipe(start_pipeline_pbia)\n",
    "    .pipe(format_datatype_dates)\n",
    "    .pipe(add_month_year_cols_users)\n",
    "    .pipe(api_calls_filtered_out, service_account, operation)\n",
    "    .pipe(lower_case_cols, \"UserId\", \"ReportName\")\n",
    ")\n",
    "\n",
    "# singleUserLogic = use_df.pipe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\">3 - Run transformation pipeline on fist node i.e. use_df.</p>\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 3.1 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">This second node in the transformation pipeline extracts useful features for better understanding of the data and machine learning experiments <br> The second node adds new columns to the data set. These columns make it possible to information related to one or multiple entities. <br> length of days with activity, length of days since last active, length of days since first active are all new coloumns derived from time delta. <br> These 3 new columns allows a measure of frequency and recency to be 2 extra features added to the dataframe.\n",
    "</td>\n",
    "</td>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 3.2 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">\n",
    "The second node ends the transformation pipeline. The dataframe is now ready for analysis and machine learning experiments. The output of both nodes are extracted as csv files. <br> This csv file forms the source data for the unsupervised machine learning process used to cluster the users into 4 quadrants.  <br>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\"><b>Note 3.3 </b></td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">The second node is stored as variable \"use_df_2\" <br>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"color:#008BCB;font-size:13px; text-align:left;\">Ref. Bash Script</td>\n",
    "<td style=\"color:rgb(88,89,91);font-size:13px; text-align:left;\">https://community.powerbi.com/t5/Service/User-activities-by-Powershell/m-p/2071415</td>\n",
    "</tr>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mlops_pbi.src.first_ingestion_point import (\n",
    "    lengthOfDays_since_firstRecord,\n",
    "    lengthOfDays_since_lastActive,\n",
    "    lengthOfDays_withActivity,\n",
    "    single_user_df,\n",
    "    single_user_frequency,\n",
    "    percent_time_inactiveFor,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2 = (\n",
    "    use_df.pipe(single_user_df)\n",
    "    .pipe(lengthOfDays_withActivity)\n",
    "    .pipe(lengthOfDays_since_lastActive)\n",
    "    .pipe(lengthOfDays_since_firstRecord)\n",
    "    .pipe(single_user_frequency)\n",
    "    .pipe(percent_time_inactiveFor)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mlops_pbi.src.first_ingestion_point import (\n",
    "    compare_df_col,\n",
    "    blank_users_df,\n",
    "    save_missing_users_df,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compare the 2 dataframes to see if any users are missing from the second node\n",
    "missing_users_list = compare_df_col(use_df, use_df_2, \"UserId\")\n",
    "\n",
    "missing_users_df = blank_users_df(use_df, missing_users_list)\n",
    "\n",
    "file_path_missing_users = r\"C:\\Users\\sibitoye\\Documents\\PBI_AuditLog_Final_Python_Output\\missing_PBI_Clean_July_August_2022.csv\"\n",
    "save_missing_users_df(df=missing_users_df, path=file_path_missing_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function to save use_df_2 to csv\n",
    "def save_df_to_csv(df, path):\n",
    "    df.to_csv(path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_saveto = r\"C:\\Users\\sibitoye\\Documents\\PBI_AuditLog_Final_Python_Output\\PBI_Clean_2022.csv\"\n",
    "save_df_to_csv(df=use_df_2, path=path_to_saveto)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2.describe(include=\"O\", datetime_is_numeric=True).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2.describe(exclude=\"O\", datetime_is_numeric=True).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\">4 - Data Visualisation</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import k_means\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use_df_2_for_ds = use_df_2.loc[use_df_2[\"%_time_inactiveFor\"] != \"NaN\"]# use_df_2[use_df_2['frequency'] == 'Nan'])\n",
    "use_df_2_for_ds = use_df_2.replace([np.inf, -np.inf], np.nan).dropna(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use_df_2_for_ds = use_df_2.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2_for_ds.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(\n",
    "    use_df_2_for_ds[\"%_time_inactiveFor\"], use_df_2_for_ds[\"frequency\"]\n",
    ")\n",
    "jointPlot = (\n",
    "    sns.jointplot(\n",
    "        x=\"%_time_inactiveFor\",\n",
    "        y=\"frequency\",\n",
    "        data=use_df_2_for_ds,\n",
    "        kind=\"reg\",\n",
    "        height=10,\n",
    "    )\n",
    ").plot_joint(sns.kdeplot, zorder=0, n_levels=6)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(\n",
    "    use_df_2_for_ds[\"lengthOfDays_since_lastActive\"],\n",
    "    use_df_2_for_ds[\"frequency\"],\n",
    ")\n",
    "jointPlot = (\n",
    "    sns.jointplot(\n",
    "        x=\"lengthOfDays_since_lastActive\",\n",
    "        y=\"frequency\",\n",
    "        data=use_df_2_for_ds,\n",
    "        kind=\"reg\",\n",
    "        height=10,\n",
    "    )\n",
    ").plot_joint(sns.kdeplot, zorder=0, n_levels=6)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"%_time_inactiveFor\",\n",
    "    \"lengthOfDays_withActivity\",\n",
    "    \"lengthOfDays_since_lastActive\",\n",
    "    \"lengthOfDays_since_firstRecord\",\n",
    "    \"frequency\",\n",
    "]\n",
    "\n",
    "\n",
    "plt.figure(1, figsize=(25, 12))\n",
    "n = 0\n",
    "for x in [\n",
    "    \"%_time_inactiveFor\",\n",
    "    \"lengthOfDays_withActivity\",\n",
    "    \"lengthOfDays_since_lastActive\",\n",
    "    \"lengthOfDays_since_firstRecord\",\n",
    "    \"frequency\",\n",
    "]:\n",
    "    n += 1\n",
    "    plt.subplot(3, 3, n)\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    sns.histplot(use_df_2_for_ds[x], bins=15)\n",
    "    plt.title(\"Distplot of {}\".format(x))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(use_df_2_for_ds[columns], hue=\"%_time_inactiveFor\", aspect=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\">5 - Machine Learning Section - Clustering</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dscols = [\n",
    "    \"UserId\",\n",
    "    \"lengthOfDays_withActivity\",\n",
    "    \"frequency\",\n",
    "    \"%_time_inactiveFor\",\n",
    "]  #'lengthOfDays_since_lastActive','lengthOfDays_since_firstRecord',"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use clustering analysis on dataframe to determine number of clusters to use\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2_for_ds[dscols]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = use_df_2_for_ds[dscols]\n",
    "X = df\n",
    "\n",
    "y = X[\"UserId\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X[\"UserId\"] = le.fit_transform(X[\"UserId\"])\n",
    "\n",
    "y = le.transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X[y]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# transform X to dataframe\n",
    "X = pd.DataFrame(X, columns=dscols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# kmeans clustering\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check model parameters\n",
    "kmeans.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "    The KMeans algorithm clusters data by trying to separate samples in n groups of equal variances, minimizing a criterion known as inertia, or within-cluster sum-of-squares Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are.\n",
    "\n",
    "    The k-means algorithm divides a set of N samples X into K disjoint clusters C, each described by the mean j of the samples in the cluster. The means are commonly called the cluster centroids.\n",
    "\n",
    "    The K-means algorithm aims to choose centroids that minimize the inertia, or within-cluster sum of squared criterion.\n",
    "\n",
    "Inertia\n",
    "\n",
    "    Inertia is not a normalized metric.\n",
    "\n",
    "    The lower values of inertia are better and zero is optimal.\n",
    "\n",
    "    But in very high-dimensional spaces, euclidean distances tend to become inflated (this is an instance of curse of dimensionality).\n",
    "\n",
    "    Running a dimensionality reduction algorithm such as PCA prior to k-means clustering can alleviate this problem and speed up the computations.\n",
    "\n",
    "    We can calculate model inertia as follows:-\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check model internal consistency\n",
    "kmeans.inertia_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "    The lesser the model inertia, the better the model fit.\n",
    "\n",
    "    We can see that the model has reasonably low inertia. So, this might be a good model fit to the data.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check quality of model fit\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# check how many of the samples were correctly labeled\n",
    "correct_labels = sum(y == labels)\n",
    "\n",
    "print(\n",
    "    \"Result: %d out of %d samples were correctly labeled.\"\n",
    "    % (correct_labels, y.size)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# elbow method to determine optimal number of clusters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cs = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=i, init=\"k-means++\", max_iter=300, n_init=10, random_state=0\n",
    "    )\n",
    "    kmeans.fit(X)\n",
    "    cs.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), cs)\n",
    "plt.title(\"The Elbow Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"inertia\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# kmeans clustering with optimal number of clusters\n",
    "kmeans = KMeans(\n",
    "    n_clusters=8,\n",
    "    init=\"k-means++\",\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    random_state=111,\n",
    "    algorithm=\"elkan\",\n",
    ").fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check quality of model fit\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# check how many of the samples were correctly labeled\n",
    "correct_labels = sum(y == labels)\n",
    "\n",
    "print(\n",
    "    \"Result: %d out of %d samples were correctly labeled.\"\n",
    "    % (correct_labels, y.size)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check how many of the samples were correctly labeled\n",
    "correct_labels = sum(y == labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show cluster centroids\n",
    "kmeans.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create cluster feature\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "X[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "X[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n",
    "\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # columns of interest\n",
    "# cols = ['Id', 'CreationTime', 'CreationTimeUTC', 'RecordType', 'Operation', 'OrganizationId', 'UserType', 'UserKey', 'Workload', 'UserId', 'ClientIP', 'UserAgent', 'Activity', 'ItemName', 'WorkSpaceName', 'DashboardName', 'DatasetName', 'ReportName',\n",
    "# 'WorkspaceId', 'ObjectId', 'DashboardId', 'DatasetId', 'ReportId', 'OrgAppPermission', 'CapacityId', 'CapacityName', 'AppName', 'IsSuccess', 'ReportType', 'RequestId', 'ActivityId', 'AppReportId', 'DistributionMethod', 'ConsumptionMethod', 'RetrieveDate']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "algorithm = KMeans(\n",
    "    n_clusters=4,\n",
    "    init=\"k-means++\",\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    random_state=111,\n",
    "    algorithm=\"elkan\",\n",
    ")\n",
    "algorithm.fit(X)\n",
    "labels1 = algorithm.labels_\n",
    "centroids1 = algorithm.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "centroids1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fileToSave = load_raw_files(allcsv_windows_glob_glob)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # function to write csv file to disk\n",
    "# def save_df_to_disk(df, path) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#\n",
    "#     :param df:\n",
    "#     :param path:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     df.to_csv(path, index=False)\n",
    "#     return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save_df_to_disk(diff_in_days, r'C:\\Users\\sibitoye\\Documents\\PBI_AuditLog_Final_Python_Output\\PBI_Clean_July_August_2022.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# export use_df_2_for_ds to csv\n",
    "# use_df_2.to_csv(r'C:\\Users\\sibitoye\\Documents\\PBI_AuditLog_Final_Python_Output\\PBI_Clean_July_August_2022.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # function to write csv file to disk\n",
    "# def save_df_to_disk(df, path) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#\n",
    "#     :param df:\n",
    "#     :param path:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     df.to_csv(path, index=False)\n",
    "#     return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNSUPERVISED MACHINE LEARNING EXPERIMENT - K-MEANS CLUSTERING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up the dataframe and fit it to kmeans clustering algorithm\n",
    "\n",
    "X1 = use_df_2_for_ds[[\"frequency\", \"%_time_inactiveFor\"]].iloc[:, :].values\n",
    "inertia = []\n",
    "for n in range(1, 15):\n",
    "    algorithm = KMeans(\n",
    "        n_clusters=n,\n",
    "        init=\"k-means++\",\n",
    "        n_init=10,\n",
    "        max_iter=300,\n",
    "        tol=0.0001,\n",
    "        random_state=111,\n",
    "        algorithm=\"lloyd\",\n",
    "    )\n",
    "    algorithm.fit(X1)\n",
    "    inertia.append(algorithm.inertia_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check the optimum number of clusters to give the best model performance\n",
    "plt.figure(1, figsize=(15, 6))\n",
    "plt.plot(np.arange(1, 15), inertia, \"o\")\n",
    "plt.plot(np.arange(1, 15), inertia, \"-\", alpha=0.5)\n",
    "plt.xlabel(\"Number of Clusters\"), plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNSUPERVISED MACHINE LEARNING EXPERIMENT WITH 4 CLUSTERS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "algorithm = KMeans(\n",
    "    n_clusters=4,\n",
    "    init=\"k-means++\",\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    random_state=111,\n",
    "    algorithm=\"elkan\",\n",
    ")\n",
    "algorithm.fit(X1)\n",
    "labels1 = algorithm.labels_\n",
    "centroids1 = algorithm.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "x_min, x_max = X1[:, 0].min() - 1, X1[:, 0].max() + 1\n",
    "y_min, y_max = X1[:, 1].min() - 1, X1[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15, 7))\n",
    "plt.clf()\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Pastel2,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.scatter(x=\"frequency\", y=\"%_time_inactiveFor\", data=df, c=labels1, s=100)\n",
    "plt.scatter(x=centroids1[:, 0], y=centroids1[:, 1], s=300, c=\"red\", alpha=0.5)\n",
    "plt.ylabel(\"%_time_inactiveFor\"), plt.xlabel(\"frequency\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "algorithm.inertia_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNSUPERVISED MACHINE LEARNING EXPERIMENT WITH 5 CLUSTERS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "algorithm = KMeans(\n",
    "    n_clusters=5,\n",
    "    init=\"k-means++\",\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    random_state=111,\n",
    "    algorithm=\"lloyd\",\n",
    ")\n",
    "algorithm.fit(X1)\n",
    "labels1 = algorithm.labels_\n",
    "centroids1 = algorithm.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "x_min, x_max = X1[:, 0].min() - 1, X1[:, 0].max() + 1\n",
    "y_min, y_max = X1[:, 1].min() - 1, X1[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15, 7))\n",
    "plt.clf()\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Pastel2,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.scatter(x=\"frequency\", y=\"%_time_inactiveFor\", data=df, c=labels1, s=100)\n",
    "plt.scatter(\n",
    "    x=centroids1[:, 0], y=centroids1[:, 1], s=300, c=\"blue\", alpha=0.75\n",
    ")\n",
    "plt.ylabel(\"%_time_inactiveFor\"), plt.xlabel(\"frequency\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "algorithm.inertia_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Dimensional Clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X3 = (\n",
    "    df[[\"frequency\", \"%_time_inactiveFor\", \"lengthOfDays_withActivity\"]]\n",
    "    .iloc[:, :]\n",
    "    .values\n",
    ")\n",
    "inertia = []\n",
    "for n in range(1, 11):\n",
    "    algorithm = KMeans(\n",
    "        n_clusters=n,\n",
    "        init=\"k-means++\",\n",
    "        n_init=10,\n",
    "        max_iter=300,\n",
    "        tol=0.0001,\n",
    "        random_state=111,\n",
    "        algorithm=\"lloyd\",\n",
    "    )\n",
    "    algorithm.fit(X3)\n",
    "    inertia.append(algorithm.inertia_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15, 6))\n",
    "plt.plot(np.arange(1, 11), inertia, \"o\")\n",
    "plt.plot(np.arange(1, 11), inertia, \"-\", alpha=0.5)\n",
    "plt.xlabel(\"Number of Clusters\"), plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "algorithm = KMeans(\n",
    "    n_clusters=7,\n",
    "    init=\"k-means++\",\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    random_state=111,\n",
    "    algorithm=\"lloyd\",\n",
    ")\n",
    "algorithm.fit(X3)\n",
    "labels3 = algorithm.labels_\n",
    "centroids3 = algorithm.cluster_centers_\n",
    "\n",
    "y_kmeans = algorithm.fit_predict(X3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check quality of model fit\n",
    "algorithm.inertia_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"cluster\"] = pd.DataFrame(y_kmeans)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# trace1 = go.Scatter3d(\n",
    "#     x= df['frequency'],\n",
    "#     y= df['lengthOfDays_withActivity'],\n",
    "#     z= df['%_time_inactiveFor'],\n",
    "#     mode='markers',\n",
    "#      marker=dict(\n",
    "#         color = df['cluster'],\n",
    "#         size= 2,\n",
    "#         line=dict(\n",
    "#             color= df['cluster'],\n",
    "#             width= 10\n",
    "#         ),\n",
    "#         opacity=0.8\n",
    "#      )\n",
    "# )\n",
    "# data = [trace1]\n",
    "# layout = go.Layout(\n",
    "#     title= 'Clusters wrt frequency, lengthOfDays and %_time_inactiveFor',\n",
    "#     scene = dict(\n",
    "#             xaxis = dict(title  = 'frequency'),\n",
    "#             yaxis = dict(title  = 'lengthOfDays'),\n",
    "#             zaxis = dict(title  = '%_time_inactiveFor')\n",
    "#         )\n",
    "# )\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# py.offline.iplot(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2_for_ds[\"cluster\"] = pd.DataFrame(y_kmeans)\n",
    "# use_df_2_for_ds.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2_for_ds.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot distribution of clusters\n",
    "sns.catplot(\n",
    "    x=\"cluster\",\n",
    "    y=\"%_time_inactiveFor\",\n",
    "    data=use_df_2_for_ds,\n",
    "    kind=\"box\",\n",
    "    aspect=1.5,\n",
    "    height=9,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot distribution of clusters\n",
    "sns.catplot(\n",
    "    x=\"cluster\",\n",
    "    y=\"lengthOfDays_withActivity\",\n",
    "    data=use_df_2_for_ds,\n",
    "    kind=\"bar\",\n",
    "    aspect=1.5,\n",
    "    height=9,\n",
    ")\n",
    "\n",
    "# -> we can see that the clusters are not very well separated\n",
    "# -> people in cluster 1 and 5 have more time with activity than people in cluster 2 and 3\n",
    "# -> people in cluster 2 and 3 are neutral compared to people in cluster 1 and 5 AND cluster 4, 6 and 0\n",
    "# -> so it is easy to conclude that cluster 1 and 5 are the most active people i.e. Great!\n",
    "# -> clusters 4, 6 and 0 are the least active people i.e. Not Great!\n",
    "# -> clusters 2 and 3 are neutral people i.e. Neutral!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot seaborn clustermap\n",
    "sns.clustermap(use_df_2.corr(), annot=True, cmap=\"coolwarm\", figsize=(20, 15))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"color:#008bcb; font-family:Arial; font-size:19px;\">6 - Export Final Output </p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# divide customers into 6 segments based on outcome of clustering analysis\n",
    "def four_quad_segment(use_df_2):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe and returns a dataframe with a new column.\n",
    "    The new column is a segment based on the frequency and %_time_inactiveFor.\n",
    "\n",
    "    :param use_df_2: df\n",
    "    :return: df\n",
    "\n",
    "    \"\"\"\n",
    "    if use_df_2[\"frequency\"] <= 30 and use_df_2[\"%_time_inactiveFor\"] <= 65:\n",
    "        return \"Great - Good Frequency, Good Recency\"\n",
    "    elif use_df_2[\"frequency\"] <= 30 and use_df_2[\"%_time_inactiveFor\"] > 65:\n",
    "        return \"Good - Good Frequency, Bad Recency\"\n",
    "    elif use_df_2[\"frequency\"] > 30 and use_df_2[\"%_time_inactiveFor\"] <= 65:\n",
    "        return \"Fair - Bad Frequency, Good Recency\"\n",
    "    else:\n",
    "        return \"Investigate - Bad Frequency, Bad Recency\"\n",
    "\n",
    "\n",
    "use_df_2[\"segment\"] = use_df_2.apply(four_quad_segment, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_df_2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use_df_2.to_csv(r'/home/sanmi/OlaJay/SimpleAnonlify/PBI_Clean_July_August_2022.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e050da93bbed0e5eb821820ec44cde41d1946549b98088841541a2d6380e7846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}